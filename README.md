# VoiceBot

VoiceBot is a **voice-in / text-out** chatbot that keeps every step of the conversation on-device. Speak into the microphone, watch the app transcribe your request locally, and receive a streaming textual reply generated by a compact Liquid AI LFM2 language model.

## Highlights

- **Hands-free prompts** – use the built-in speech recognizer to dictate messages without leaving the chat timeline.
- **Device-local intelligence** – the bundled LFM2 small model performs inference on-device, keeping prompts and responses private.
- **Streaming replies** – SwiftUI and Swift Concurrency combine to show partial responses as they are generated.
- **Modern Swift stack** – actors, async/await, and @Observable-backed state keep the experience responsive and predictable.

## Conversation Flow

1. **Listen** – `MicrophoneInputBar` captures audio and transcribes it using Apple’s on-device Speech framework.
2. **Understand** – the transcript feeds `ModelRuntimeService`, which routes prompts to the Liquid AI LFM2 model for interpretation and response generation.
3. **Respond** – the chat interface streams the model’s textual output back to the user in real time.

## Project Structure

```
VoiceBot/
├── VoiceBot.xcworkspace      # Open this workspace in Xcode
├── VoiceBot/                 # Minimal app shell
├── VoiceBotPackage/          # Feature code, services, and views
└── VoiceBotUITests/          # UI automation targets
```

- `ContentView.swift` coordinates navigation between the conversation and settings screens.
- `MicrophoneInputBar.swift` manages the speech capture lifecycle and authorization.
- `ModelRuntimeService.swift` wraps the LFM2 runtime adapter and orchestrates inference sessions.

## Running the Demo

1. Install Xcode 16 beta (or newer) with the iOS 18 simulator.
2. Open `VoiceBot.xcworkspace` and select the **VoiceBot** scheme.
3. Build & run on an iPhone 16 simulator to initialize the packaged LFM2 model.
4. Press the microphone button, speak a prompt, and watch VoiceBot stream the generated text reply.

## Example Prompts

- “Summarize the latest app release notes.”
- “Give me three ideas for a voice-only productivity assistant.”
- “Draft a friendly reminder message for tomorrow’s meeting.”

## Local AI Stack

| Layer | Technology | Notes |
| --- | --- | --- |
| Speech capture | Apple Speech framework | Uses on-device transcription with partial-result streaming |
| Language model | Liquid AI LFM2 (small) | Bundled with the app for fully local inference |
| Runtime orchestration | Swift Concurrency + actors | Ensures thread-safe access to the model and chat state |

## Contributing

Enhancements to the chat experience, prompt engineering, or runtime performance are welcome. Please keep inference paths on-device and align with the project’s SwiftUI and concurrency conventions.

## License

VoiceBot is available under the [MIT License](./LICENSE).
